{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0kbY0KYfXUvL"
   },
   "source": [
    "# Transfer Learning - VGGNet\n",
    "\n",
    "**Załadujemy gotowy model (w tym przypadku VGGNet19) i dostroimy go do nowego zadania klasyfikacji binarnej - przykład z książki \"Uczenie głębokie i sztuczna inteligencja. Interaktywny przewodnik ilustrowany\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gwkO_cNnXUvQ"
   },
   "source": [
    "### Ładujemy zależności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QopB53apXUvV"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yv-1x_UVXUvf"
   },
   "source": [
    "### Ładujemy wytrenowany model VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8EBF8Nq_XUvh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 7s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg19 = VGG19(include_top=False, #ostatnie warstwy zagęszczone, specyficzne dla zbioru, nie zostają załadowane\n",
    "              weights='imagenet',\n",
    "              input_shape=(224,224,3),\n",
    "              pooling=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Nas5PppXUvo"
   },
   "source": [
    "### \"Zamrażamy\" warstwy modelu VGGNet19 - nie będą się douczać"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIfAuTcpXUvq"
   },
   "outputs": [],
   "source": [
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x273501e1160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbKPfaJ4XUvw"
   },
   "source": [
    "### Tworzymy całościowy model, \"u góry\" dodajemy VGGNet19, a dalej własne warstwy\n",
    "\n",
    "**Zadanie 3. Dodaj warstwę spłaszczającą, dropout 0.5 i warstwę pozwalającą sklasyfikować binarnie obiekty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UwPBdAAXUvy"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(vgg19)\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "bcxO9igkahgS",
    "outputId": "0ac37247-f4ad-440b-ebdb-a9c06f56bc7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,074,562\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hRykcyAXUv3"
   },
   "source": [
    "### Kompilujemy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lMeMTHYXUv5"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qjso4EqXUwA"
   },
   "source": [
    "### Pobierz zbiór danych z [Kaggle'a](https://www.kaggle.com/datasets/dansbecker/hot-dog-not-hot-dog) i rozpakuj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zbiór jest mały, więc tworzymy instancje klasy ImageDataGenerator, które pozwolą nam powiększyć dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXNPazweXUwH"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    data_format='channels_last',\n",
    "    rotation_range=30,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    data_format='channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deklarujemy rozmiar paczki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Powiększamy dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "gXyJj7ewXUwR",
    "outputId": "9b479e01-c188-4ad6-e90f-6ec454975abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory= 'archive/train',\n",
    "    target_size=(224, 224),\n",
    "    classes=['hot_dog','not_hot_dog'],\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42)\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory= 'archive/test',\n",
    "    target_size=(224, 224),\n",
    "    classes=['hot_dog','not_hot_dog'],\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 4. Wypisz co oznaczają wszystkie zadeklarowane parametry generatorów danych**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>directory</b> - ścieżka w której znajdują się foldery klas\n",
    "<br>\n",
    "<b>target_size</b>  - rozmiar obrazów wchodzących, tj. zmienione do 224x224\n",
    "<br>\n",
    "<b>classess</b>  - dwie klasy daych, foldery w ścieżce zawierające zdjęcia hot dogów lub innych dań\n",
    "<br>\n",
    "<b>class_mode</b>  - deklarowany w zależności od ilości klas\n",
    "<br>\n",
    "<b>batch_size</b>  - liczba która dokładnie dzieli całkowitą liczbę obrazów\n",
    "<br>\n",
    "<b>shuffle</b>  - czy wymieszać kolejność plików\n",
    "<br>\n",
    "<b>seed</b>  - kolejny czynnik wpływający na randomowość obrazów poddawanych treningowi/walidacji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uczymy model z danymi z generatora (dla ułatwienia używamy do tego oddzielnej funkcji, choć będzie w następnej wersji tensorflowa usunięta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "md-_KzmjXUwW",
    "outputId": "cbcca782-2fe2-418a-811a-6132c2128da9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angel\\AppData\\Local\\Temp/ipykernel_16572/2768083069.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator, steps_per_epoch=15, epochs=16, validation_data=valid_generator, validation_steps=15)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "15/15 [==============================] - 108s 7s/step - loss: 1.2616 - accuracy: 0.5408 - val_loss: 1.3508 - val_accuracy: 0.5063\n",
      "Epoch 2/16\n",
      "15/15 [==============================] - 108s 7s/step - loss: 0.7543 - accuracy: 0.6888 - val_loss: 1.9330 - val_accuracy: 0.5021\n",
      "Epoch 3/16\n",
      "15/15 [==============================] - 108s 7s/step - loss: 0.8922 - accuracy: 0.6545 - val_loss: 0.5990 - val_accuracy: 0.7042\n",
      "Epoch 4/16\n",
      "15/15 [==============================] - 108s 7s/step - loss: 0.4735 - accuracy: 0.7854 - val_loss: 0.4511 - val_accuracy: 0.7792\n",
      "Epoch 5/16\n",
      "15/15 [==============================] - 108s 7s/step - loss: 0.6344 - accuracy: 0.7296 - val_loss: 0.7820 - val_accuracy: 0.6854\n",
      "Epoch 6/16\n",
      "15/15 [==============================] - 109s 7s/step - loss: 0.4061 - accuracy: 0.8112 - val_loss: 0.9354 - val_accuracy: 0.6479\n",
      "Epoch 7/16\n",
      "15/15 [==============================] - 108s 8s/step - loss: 0.6905 - accuracy: 0.7189 - val_loss: 0.4748 - val_accuracy: 0.7812\n",
      "Epoch 8/16\n",
      "15/15 [==============================] - 109s 7s/step - loss: 0.3897 - accuracy: 0.8369 - val_loss: 0.7972 - val_accuracy: 0.6979\n",
      "Epoch 9/16\n",
      "15/15 [==============================] - 109s 8s/step - loss: 0.3373 - accuracy: 0.8433 - val_loss: 0.4779 - val_accuracy: 0.7792\n",
      "Epoch 10/16\n",
      "15/15 [==============================] - 111s 8s/step - loss: 0.3220 - accuracy: 0.8627 - val_loss: 0.7277 - val_accuracy: 0.7188\n",
      "Epoch 11/16\n",
      "15/15 [==============================] - 110s 8s/step - loss: 0.3876 - accuracy: 0.8348 - val_loss: 0.7092 - val_accuracy: 0.7292\n",
      "Epoch 12/16\n",
      "15/15 [==============================] - 110s 8s/step - loss: 0.2985 - accuracy: 0.8734 - val_loss: 0.4530 - val_accuracy: 0.7896\n",
      "Epoch 13/16\n",
      "15/15 [==============================] - 109s 8s/step - loss: 0.3965 - accuracy: 0.8433 - val_loss: 0.5440 - val_accuracy: 0.7750\n",
      "Epoch 14/16\n",
      "15/15 [==============================] - 109s 8s/step - loss: 0.2349 - accuracy: 0.9077 - val_loss: 0.5511 - val_accuracy: 0.7646\n",
      "Epoch 15/16\n",
      "15/15 [==============================] - 108s 7s/step - loss: 0.2942 - accuracy: 0.8691 - val_loss: 0.9340 - val_accuracy: 0.6958\n",
      "Epoch 16/16\n",
      "15/15 [==============================] - 113s 8s/step - loss: 0.3230 - accuracy: 0.8479 - val_loss: 0.6204 - val_accuracy: 0.7646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2735049d250>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=15, epochs=16, validation_data=valid_generator, validation_steps=15)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "transfer_learning_in_tensorflow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "neural_networks",
   "language": "python",
   "name": "neural_networks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
